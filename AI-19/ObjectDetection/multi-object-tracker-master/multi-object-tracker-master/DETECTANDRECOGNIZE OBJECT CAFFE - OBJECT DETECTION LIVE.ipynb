{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 as cv\n",
    "from scipy.spatial import distance\n",
    "import numpy as np\n",
    "from collections import OrderedDict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Object Tracking Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Tracker:\n",
    "    def __init__(self, maxLost = 30):           # maxLost: maximum object lost counted when the object is being tracked\n",
    "        self.nextObjectID = 0                   # ID of next object\n",
    "        self.objects = OrderedDict()            # stores ID:Locations\n",
    "        self.lost = OrderedDict()               # stores ID:Lost_count\n",
    "        \n",
    "        self.maxLost = maxLost                  # maximum number of frames object was not detected.\n",
    "        \n",
    "    def addObject(self, new_object_location):\n",
    "        self.objects[self.nextObjectID] = new_object_location    # store new object location\n",
    "        self.lost[self.nextObjectID] = 0                         # initialize frame_counts for when new object is undetected\n",
    "        \n",
    "        self.nextObjectID += 1\n",
    "    \n",
    "    def removeObject(self, objectID):                          # remove tracker data after object is lost\n",
    "        del self.objects[objectID]\n",
    "        del self.lost[objectID]\n",
    "    \n",
    "    @staticmethod\n",
    "    def getLocation(bounding_box):\n",
    "        xlt, ylt, xrb, yrb = bounding_box\n",
    "        return (int((xlt + xrb) / 2.0), int((ylt + yrb) / 2.0))\n",
    "    \n",
    "    def update(self,  detections):\n",
    "        \n",
    "        if len(detections) == 0:   # if no object detected in the frame\n",
    "            for objectID in self.lost.keys():\n",
    "                self.lost[objectID] +=1\n",
    "                if self.lost[objectID] > self.maxLost: self.removeObject(objectID)\n",
    "            \n",
    "            return self.objects\n",
    "        \n",
    "        new_object_locations = np.zeros((len(detections), 2), dtype=\"int\")     # current object locations\n",
    "        \n",
    "        for (i, detection) in enumerate(detections): new_object_locations[i] = self.getLocation(detection)\n",
    "            \n",
    "        if len(self.objects)==0:\n",
    "            for i in range(0, len(detections)): self.addObject(new_object_locations[i])\n",
    "        else:\n",
    "            objectIDs = list(self.objects.keys())\n",
    "            previous_object_locations = np.array(list(self.objects.values()))\n",
    "            \n",
    "            D = distance.cdist(previous_object_locations, new_object_locations) # pairwise distance between previous and current\n",
    "            \n",
    "            row_idx = D.min(axis=1).argsort()   # (minimum distance of previous from current).sort_as_per_index\n",
    "            \n",
    "            cols_idx = D.argmin(axis=1)[row_idx]   # index of minimum distance of previous from current\n",
    "            \n",
    "            assignedRows, assignedCols = set(), set()\n",
    "            \n",
    "            for (row, col) in zip(row_idx, cols_idx):\n",
    "                \n",
    "                if row in assignedRows or col in assignedCols:\n",
    "                    continue\n",
    "                \n",
    "                objectID = objectIDs[row]\n",
    "                self.objects[objectID] = new_object_locations[col]\n",
    "                self.lost[objectID] = 0\n",
    "                \n",
    "                assignedRows.add(row)\n",
    "                assignedCols.add(col)\n",
    "                \n",
    "            unassignedRows = set(range(0, D.shape[0])).difference(assignedRows)\n",
    "            unassignedCols = set(range(0, D.shape[1])).difference(assignedCols)\n",
    "            \n",
    "            \n",
    "            if D.shape[0]>=D.shape[1]:\n",
    "                for row in unassignedRows:\n",
    "                    objectID = objectIDs[row]\n",
    "                    self.lost[objectID] += 1\n",
    "                    \n",
    "                    if self.lost[objectID] > self.maxLost:\n",
    "                        self.removeObject(objectID)\n",
    "                        \n",
    "            else:\n",
    "                for col in unassignedCols:\n",
    "                    self.addObject(new_object_locations[col])\n",
    "            \n",
    "        return self.objects\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Loading Object Detector Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Face Detection and Tracking\n",
    "\n",
    "Here, the Face Detection Caffe Model is used.\n",
    "\n",
    "The files are taken from the following link:\n",
    "https://github.com/opencv/opencv_3rdparty/tree/dnn_samples_face_detector_20170830"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "caffemodel = {\"prototxt\":\"./caffemodel_dir/deploy.prototxt\",\n",
    "              \"model\":\"./caffemodel_dir/res10_300x300_ssd_iter_140000.caffemodel\",\n",
    "              \"acc_threshold\":0.50                  # neglected detections with probability less than acc_threshold value\n",
    "             }\n",
    "\n",
    "net = cv.dnn.readNetFromCaffe(caffemodel[\"prototxt\"], caffemodel[\"model\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Instantiate the Tracker Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "maxLost = 60   # maximum number of object losts counted when the object is being tracked\n",
    "tracker = Tracker(maxLost = maxLost)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Initiate opencv video capture object\n",
    "\n",
    "The `video_src` can take two values:\n",
    "1. If `video_src=0`: OpenCV accesses the camera connected through USB\n",
    "2. If `video_src='video_file_path'`: OpenCV will access the video file at the given path (can be MP4, AVI, etc format)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "video_src = 0\n",
    "cap = cv.VideoCapture(video_src)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Start object detection and tracking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cannot read the video feed.\n"
     ]
    }
   ],
   "source": [
    "(H, W) = (None, None)  # input image height and width for the network\n",
    "\n",
    "while(True):\n",
    "    \n",
    "    ok, image = cap.read()\n",
    "    \n",
    "    if not ok:\n",
    "        print(\"Cannot read the video feed.\")\n",
    "        break\n",
    "    \n",
    "    image = cv.resize(image, (400, 400), interpolation = cv.INTER_AREA)\n",
    "    \n",
    "    if W is None or H is None: (H, W) = image.shape[:2]\n",
    "    \n",
    "    blob = cv.dnn.blobFromImage(image, 1.0, (W, H), (104.0, 177.0, 123.0))\n",
    "    \n",
    "    net.setInput(blob)\n",
    "    detections = net.forward()                   # detect objects using object detection model\n",
    "    \n",
    "    detections_bbox = []                         # bounding box for detections\n",
    "    \n",
    "    for i in range(0, detections.shape[2]):\n",
    "        if detections[0, 0, i, 2] > caffemodel[\"acc_threshold\"]:\n",
    "            box = detections[0, 0, i, 3:7] * np.array([W, H, W, H])\n",
    "            detections_bbox.append(box.astype(\"int\"))\n",
    "            \n",
    "            # draw a bounding box surrounding the object so we can visualize it\n",
    "            (startX, startY, endX, endY) = box.astype(\"int\")\n",
    "            cv.rectangle(image, (startX, startY), (endX, endY), (0, 255, 0), 2)    \n",
    "    \n",
    "    objects = tracker.update(detections_bbox)                  # update tracker based on the newly detected objects\n",
    "    \n",
    "    for (objectID, centroid) in objects.items():\n",
    "        text = \"ID {}\".format(objectID)\n",
    "        cv.putText(image, text, (centroid[0] - 10, centroid[1] - 10), cv.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)\n",
    "        cv.circle(image, (centroid[0], centroid[1]), 4, (0, 255, 0), -1)\n",
    "        \n",
    "    cv.imshow(\"image\", image)\n",
    "    \n",
    "    if cv.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "        \n",
    "cap.release()\n",
    "cv.destroyWindow(\"image\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
